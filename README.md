# Motion-MDRNN
*Please view the notebook [here!](https://nbviewer.jupyter.org/github/benediktewallace/Motion-MDRNN-sos/blob/master/SOSpredict_and_generate.ipynb)*  


In the notebook `sampling-from-MDRNN.ipynb` you can view video examples generated using a Mixture Density Recurrent Neural Network trained on a dataset of improvised dance motion capture data from which it is possible to generate novel movement sequences.  
By utilising several different sampling strategies we examine the variations that emerge and explore the effect these strategies have on the generated motion.

## Viewing the notebook
Use [Jupyter Notebook Viewer](https://github.com/jupyter/nbviewer/) to view the notebook with video exampes.


## Running the notebook
This is an [sos-notebook](https://vatlab.github.io/sos-docs/) which can run different kernels in different cells. Please see the [docs](https://vatlab.github.io/sos-docs/running.html#content) for installation guides. 

---

Other dependencies:

- [MATLAB library: MoCap Toolbox](https://www.jyu.fi/hytk/fi/laitokset/mutku/en/research/materials/mocaptoolbox)  
- [Tensorflow >= 2.0](https://www.tensorflow.org/)
- [Keras Mixture Density Network Layer](https://github.com/cpmpercussion/keras-mdn-layer#keras-mixture-density-network-layer)
---
